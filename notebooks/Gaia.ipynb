{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfed9634-56d1-44bb-9a03-6a95a4d34e82",
   "metadata": {},
   "source": [
    "# Gaia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e8c46d-2fe4-4bd4-8043-b566db6a2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astroquery.gaia import Gaia\n",
    "from astropy.coordinates import SkyCoord\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def process_gaia(\n",
    "    dataframe,\n",
    "    limit_distance_pc=10000,\n",
    "    output_prefix=None,\n",
    "    batch_size=10,\n",
    "    max_workers=5,\n",
    "    sleep_between_batches=5,\n",
    "    n_shells=8,\n",
    "    log_eirp_shells=None,\n",
    "    split_by_band=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Remember to login to the Gaia archive before using this function!\n",
    "    Gaia.login(user='userName', password='userPassword')\n",
    "        \n",
    "    Parallelized, batch-based Gaia cone search and post-processing pipeline for field-based SETI analysis,\n",
    "    following the methodology of Wlodarczyk-Sroka et al. (2020, MNRAS, 498, 5720) and incorporating\n",
    "    distance estimates from Bailer-Jones et al. (2021, AJ, 161, 147, Gaia EDR3).\n",
    "    \n",
    "    This function enables automated, scalable querying of the Gaia EDR3 catalog with rigorous field geometry,\n",
    "    beam attenuation, and EIRPmin constraint analysis per observing field and receiving band, allowing both\n",
    "    combined (all bands) and per-band results as in recent large-scale SETI surveys.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pandas.DataFrame\n",
    "        Required columns:\n",
    "        - 'ra'           [degrees]: ICRS Right Ascension (field/beam center, converted internally to float)\n",
    "        - 'dec'          [degrees]: ICRS Declination (field/beam center, converted internally to float)\n",
    "        - 'fwhm_arcmin'  [arcminutes]: Beamwidth (FWHM) of the field, converted internally to float\n",
    "        - 'fmin'         [W * m^−2]: Minimum detectable flux density at the field (per band), converted internally to float\n",
    "        - 'nu_rel'       [unitless]: total bandwidth of the receiver normalized by the central, converted internally to float\n",
    "            observing frequency (used in Transmitter Rate and CWTFM scaling)\n",
    "        - 'field name': Unique field identifier, converted internally to str\n",
    "        - 'receiving_band': Name of the observing band (e.g., 'L', 'S'); allows per-band separation, converted internally to str\n",
    "    \n",
    "        Acceptable types: all columns must be convertible to their indicated types.\n",
    "    \n",
    "    limit_distance_pc : float, optional\n",
    "        Maximum stellar distance (parsecs) to include from Gaia (default: 10 kpc, as in WG&S 2020)\n",
    "    output_prefix : str, optional\n",
    "        If provided, concatenated results are saved in CSV files using this prefix (per band, or combined)\n",
    "        all_df is saved according to output_prefix_band name_gaia_df.csv\n",
    "        shell_results is saved according to output_prefix_band name_gaia_shell_results.csv\n",
    "    batch_size : int, optional\n",
    "        Number of fields to process in each Gaia ADQL/cone search batch (default: 10, scale up as needed)\n",
    "    max_workers : int, optional\n",
    "        Maximum number of concurrent batch query threads (default: 5, scale up as needed)\n",
    "    sleep_between_batches : float, optional\n",
    "        Seconds to pause between launching concurrent batches (default: 5, scale down as needed)\n",
    "    n_shells : int, optional\n",
    "        Number of log10(EIRPmin) shells, if not providing log_eirp_shells explicitly (default: 8 as per WG&S 2020)\n",
    "    log_eirp_shells : array-like, optional\n",
    "        If specified, manual edges (log₁₀ EIRPmin [W]) for sensitivity shell analysis. Per WG&S 2020, for max distances less \n",
    "        than 10 kpc the standard range of EIRPmin shells is np.linspace(11, 18, 8)\n",
    "    split_by_band : bool, optional\n",
    "        If True, runs the complete analysis per unique value of 'receiving_band' (returns dict per band).\n",
    "        If False, combines all bands in the input for a single global analysis.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If split_by_band == False:\n",
    "        all_df : pandas.DataFrame\n",
    "            Detected Gaia sources with beam geometry/attenuation factors, joined with input field metadata.\n",
    "            Columns include:\n",
    "                - source_id            [int]\n",
    "                - ra, dec              [deg]\n",
    "                - r_med_geo, r_lo_geo, r_hi_geo    [pc; median/lo/hi geometric distance]\n",
    "                - phot_g_mean_mag, bp_rp, abs_g_photogeo, abs_g_geo [mag]\n",
    "                - field_name           [str]\n",
    "                - fmin, nu_rel, fwhm_arcmin\n",
    "                - theta_arcmin         [arcmin]: offset from field center (beam attenuation)\n",
    "                - scaling_factor       [unitless]: Gaussian beam response normalized based on beam center\n",
    "        shell_results : pandas.DataFrame\n",
    "            Table of EIRPmin shells:\n",
    "                - log_EIRPmin_shell    [log10(W)] (shell edges)\n",
    "                - n_stars              (stars at EIRPmin ≤ shell edge)\n",
    "                - n_stars_pos_err, n_stars_neg_err (uncertainty based on distance bounds)\n",
    "                - log_TR, log_TR_pos_err, log_TR_neg_err\n",
    "                - CWTFM, CWTFM_pos_err, CWTFM_neg_err\n",
    "                - max_distance_pc       [pc]: maximal distance for each shell\n",
    "    \n",
    "    If split_by_band == True:\n",
    "        all_df_dict : dict\n",
    "            Per-band DataFrame for each unique 'receiving_band'\n",
    "        shell_results_dict : dict\n",
    "            Per-band shell analysis DataFrame\n",
    "        Access each DataFrame by all_df_dict['band 1']...,\n",
    "            shell_results_dict['band 1']...\n",
    "    \n",
    "    Methods & Variables (per WG&S 2020; Bailer-Jones et al. 2021)\n",
    "    -------------------------------------------------------------\n",
    "    - Stellar selection/search: Each field is queried via Gaia EDR3, retrieving all sources within\n",
    "      the primary beam FWHM and satisfying ruwe < 1.4 (astrometric quality flag). Fields are processed\n",
    "      in batches for efficiency using multi-threading (see §2.3 of WG&S 2020).\n",
    "    - Distance estimation: Stellar distances taken from Bailer-Jones et al. 2021 (geometric and photogeometric), columns r_med_geo, r_lo_geo, r_hi_geo [pc].\n",
    "    - Beam response calculation: For each source, the beam attenuation is\n",
    "        scaling_factor = exp(−4 ln(2) * (θ/FWHM)^2)\n",
    "        where θ is the angular separation from beam center (arcmin), and FWHM is the standard field width in arcmin where beam response drops to 50% \n",
    "        (WG&S Eq. 1 and §2.2).\n",
    "    - Minimum detectable EIRP: For each star and each shell:\n",
    "          log₁₀(EIRPmin) = log₁₀(4π) + 2 log₁₀(distance_m) + log₁₀(fmin) – log₁₀(beam_response)\n",
    "      where distance_m is in meters (1 pc = 3.086e16 m), fmin in W * m^-2.\n",
    "    - Sensitivity shells: log10(EIRPmin) shells are constructed either manually, or using\n",
    "        np.linspace(11, 18, 8) for distances < 10kpc (WG&S Table 2).\n",
    "    - Error propagation: For each shell, uncertainties in distance (lo/hi) propagate into star counts and log_TR, CWTFM, \n",
    "        and their errors. Shell statistics (n_stars, log_TR, etc.) include star-count errors where postive error in n_stars (n_stars_pos_error) comes\n",
    "        from r_med_geo > shell value, and r_lo_geo <= shell value. Negative error in star-count (n_stars_neg_error) comes from r_med_geo <= shell value, and \n",
    "        r_hi_geo > shell value. Log_TR_pos_err, log_TR_neg_err, CWTFM_pos_err, CWTFM_neg_err all come from the difference between the nominal values\n",
    "        evaluated at r_med_geo and the upper and lower values of n_stars(n_stars_upper and n_stars_lower), \n",
    "        where n_stars_upper = n_stars + n_stars_pos_error and \n",
    "        n_stars_lower = n_stars - n_stars_neg_error.\n",
    "    - Population constraint metrics:\n",
    "        - log_TR: log₁₀(1 / (N_stars * nu_rel)), where N_stars is the number of stars below the shell EIRPmin value (WG&S Eq. 3).\n",
    "        - CWTFM (Continuous Waveform Transmitter Figure of Merit):\n",
    "          (shell EIRPmin / 1e13) * (0.5 / nu_rel) * (1000 / N_stars)\n",
    "    \n",
    "    Units\n",
    "    -----\n",
    "    - RA, Dec: degrees [deg]\n",
    "    - fwhm_arcmin: arcminutes [']\n",
    "    - distance: parsecs [pc] (converted to meters [m] for EIRPmin calculation)\n",
    "    - fmin: [W * m^-2]\n",
    "    - nu_rel: nu_rel(BW/f): unitless, where f represents the observed frequency, \n",
    "        and BW denotes the total bandwidth in GHz\n",
    "    - scaling_factor: unitless (0.5 ≤ scaling factor ≤ 1)\n",
    "    - theta_arcmin: arcminutes [']\n",
    "    - log_EIRPmin: log₁₀(W)\n",
    "    - log_TR: log₁₀(1/(N_stars * nu_rel)) [dimensionless]\n",
    "    - CWTFM: unitless\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - The 'field name' and 'receiving_band' columns are always mapped to string dtype internally. All other columns are converted to floats.\n",
    "    - All results, per-band or combined, ensure unique source_id entries (no duplicate Gaia sources per band).\n",
    "    - Any column with missing/failed data (e.g., stars without BJ21 distance) is excluded from shell analysis.\n",
    "    - If split_by_band is True, output dicts can be accessed by their receiving_band name key (e.g., all_df_dict['L']).\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    - Wlodarczyk-Sroka, B. S., Garrett, M. A., Siemion, A. P. V. (2020), \"Extending the Breakthrough Listen nearby star survey \n",
    "        to other stellar objects in the field,\" MNRAS, 498, 5720. https://doi.org/10.1093/mnras/staa2672\n",
    "    - Bailer-Jones, C.A.L., et al. (2021), \"Estimating Distances from Parallaxes. V. Geometric and Photogeometric Distances to \n",
    "        1.47 Billion Stars in Gaia Early Data Release 3,\" AJ, 161, 147. https://iopscience.iop.org/article/10.3847/1538-3881/abd806\n",
    "    - See also SETI EIRPmin and shell statistics methodology as adopted in Gajjar & Siemion (2023), Enriquez et al. (2018), and relatedSETI literature.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.loc[:, 'field name'] = dataframe.loc[:, 'field name'].astype(str)\n",
    "    dataframe.loc[:, 'receiving_band'] = dataframe.loc[:, 'receiving_band'].astype(str)\n",
    "    dataframe.loc[:, 'ra'] = dataframe.loc[:, 'ra'].astype(float)\n",
    "    dataframe.loc[:, 'dec'] = dataframe.loc[:, 'dec'].astype(float)\n",
    "    dataframe.loc[:, 'fwhm_arcmin'] = dataframe.loc[:, 'fwhm_arcmin'].astype(float)\n",
    "    dataframe.loc[:, 'fmin'] = dataframe.loc[:, 'fmin'].astype(float)\n",
    "    dataframe.loc[:, 'nu_rel'] = dataframe.loc[:, 'nu_rel'].astype(float)\n",
    "\n",
    "    def run_pipeline(df_band, band_name, output_prefix=None, \n",
    "    log_eirp_shells_outer=None, n_shells_outer=None):\n",
    "\n",
    "        log_eirp_shells_local = log_eirp_shells_outer\n",
    "        n_shells_local = n_shells_outer\n",
    "        n_total = len(df_band)\n",
    "        batch_files = []\n",
    "\n",
    "        def angular_separation_arcmin(ra1, dec1, ra2, dec2):\n",
    "            c1 = SkyCoord(ra1, dec1, unit='deg')\n",
    "            c2 = SkyCoord(ra2, dec2, unit='deg')\n",
    "            return c1.separation(c2).arcminute\n",
    "\n",
    "        def beam_scaling(beam_ra, beam_dec, star_ra, star_dec, fwhm_arcmin):\n",
    "            theta_arcmin = angular_separation_arcmin(beam_ra, beam_dec, star_ra, star_dec)\n",
    "            exponent = -4 * np.log(2) * (theta_arcmin / fwhm_arcmin)**2\n",
    "            scaling_factor = np.exp(exponent)\n",
    "            return theta_arcmin, scaling_factor\n",
    "\n",
    "        def process_beam_astropy_vectorized(beam_ra, beam_dec, fwhm_arcmin, catalog_df):\n",
    "            star_ras = catalog_df['ra'].to_numpy()\n",
    "            star_decs = catalog_df['dec'].to_numpy()\n",
    "            theta, scaling = beam_scaling(beam_ra, beam_dec, star_ras, star_decs, fwhm_arcmin)\n",
    "            catalog_df = catalog_df.copy()\n",
    "            catalog_df.loc[:, 'theta_arcmin'] = theta\n",
    "            catalog_df.loc[:, 'scaling_factor'] = scaling\n",
    "            return catalog_df\n",
    "        \n",
    "        def build_multi_cone_adql(ra_list, dec_list, fwhm_list, field_name_list):\n",
    "            queries = []\n",
    "            for idx, (ra, dec, fwhm, fname) in enumerate(zip(ra_list, dec_list, fwhm_list, field_name_list)):\n",
    "                radius_deg = (fwhm / 2.0) / 60.0\n",
    "                queries.append(f\"\"\"\n",
    "                SELECT\n",
    "                  source_id, ra, dec,\n",
    "                  r_med_geo, r_lo_geo, r_hi_geo,\n",
    "                  r_med_photogeo, r_lo_photogeo, r_hi_photogeo,\n",
    "                  phot_bp_mean_mag - phot_rp_mean_mag AS bp_rp,\n",
    "                  phot_g_mean_mag,\n",
    "                  phot_g_mean_mag - 5 * LOG10(r_med_geo) + 5 AS abs_g_geo,\n",
    "                  phot_g_mean_mag - 5 * LOG10(r_med_photogeo) + 5 AS abs_g_photogeo,\n",
    "                  '{fname}' AS field_name\n",
    "                FROM gaiaedr3.gaia_source\n",
    "                JOIN external.gaiaedr3_distance USING (source_id)\n",
    "                WHERE\n",
    "                  ruwe < 1.4 AND\n",
    "                  1 = CONTAINS(\n",
    "                    POINT('ICRS', {ra}, {dec}),\n",
    "                    CIRCLE('ICRS', ra, dec, {radius_deg})\n",
    "                  )\n",
    "                \"\"\")\n",
    "            return \" UNION ALL \".join(queries)\n",
    "\n",
    "        def fetch_batch(ra_batch, dec_batch, fwhm_batch, field_name_batch, batch_idx):\n",
    "            adql = build_multi_cone_adql(ra_batch, dec_batch, fwhm_batch, field_name_batch)\n",
    "            job = Gaia.launch_job_async(adql)\n",
    "            result = job.get_results().to_pandas()\n",
    "            result = result.drop_duplicates(subset=['source_id'])\n",
    "            for ra, dec, fwhm, fname in zip(ra_batch, dec_batch, fwhm_batch, field_name_batch):\n",
    "                mask = result['field_name'] == fname\n",
    "                if mask.any():\n",
    "                    subset = result.loc[mask]\n",
    "                    processed = process_beam_astropy_vectorized(ra, dec, fwhm, subset)\n",
    "                    processed = processed.loc[subset.index]\n",
    "                    result.loc[mask, ['theta_arcmin', 'scaling_factor']] = processed[['theta_arcmin', 'scaling_factor']].to_numpy()\n",
    "            filtered_df = result[(result['r_med_geo'] <= limit_distance_pc) & (result['r_med_geo'] >= 0)].copy()\n",
    "            # if output_prefix is not None:\n",
    "                # filename = f\"{output_prefix}_{band_name}_batch{batch_idx}.csv\"\n",
    "                # filtered_df.to_csv(filename, index=False)\n",
    "            return filtered_df\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = []\n",
    "            for batch_start in range(0, n_total, batch_size):\n",
    "                batch_end = min(batch_start + batch_size, n_total)\n",
    "                ra_batch = df_band['ra'].iloc[batch_start:batch_end].to_numpy()\n",
    "                dec_batch = df_band['dec'].iloc[batch_start:batch_end].to_numpy()\n",
    "                fwhm_batch = df_band['fwhm_arcmin'].iloc[batch_start:batch_end].to_numpy()\n",
    "                field_name_batch = df_band['field name'].iloc[batch_start:batch_end].to_numpy()\n",
    "                futures.append(executor.submit(\n",
    "                    fetch_batch, ra_batch, dec_batch, fwhm_batch, field_name_batch, batch_start // batch_size\n",
    "                ))\n",
    "                time.sleep(sleep_between_batches)\n",
    "            dfs = []\n",
    "            for future in as_completed(futures):\n",
    "                dfb = future.result()\n",
    "                dfs.append(dfb)\n",
    "            if not dfs:\n",
    "                return pd.DataFrame(), pd.DataFrame()\n",
    "            all_df = pd.concat(dfs, ignore_index=True)\n",
    "            all_df['field_name'] = all_df['field_name'].astype(str)\n",
    "            for col in ['theta_arcmin', 'scaling_factor']:\n",
    "                if col not in all_df.columns:\n",
    "                    all_df[col] = np.nan\n",
    "            input_field_map = df_band.set_index('field name')[['fmin','nu_rel','fwhm_arcmin']].copy()\n",
    "            all_df = all_df.merge(input_field_map, left_on='field_name', right_index=True, how='left')\n",
    "            # Move field_name to first column\n",
    "            col_to_move = all_df.pop('field_name')\n",
    "            all_df.insert(0, 'field_name', col_to_move)\n",
    "            all_df.drop_duplicates(subset=['source_id'], inplace=True)\n",
    "        \n",
    "        # EIRPmin + Shell Analysis\n",
    "        def calculate_eirpmin_log(df):\n",
    "            df = df.copy()\n",
    "            log_4pi = np.log10(4 * np.pi)\n",
    "            for key, col in zip(['med', 'lo', 'hi'], ['r_med_geo', 'r_lo_geo', 'r_hi_geo']):\n",
    "                d_m = df[col].to_numpy() * 3.086e16  # pc to meters\n",
    "                fmin_vals = df['fmin'].to_numpy()\n",
    "                df[f'logEIRPmin_{key}'] = log_4pi + 2 * np.log10(d_m) + np.log10(fmin_vals) - np.log10(df['scaling_factor'])\n",
    "            return df\n",
    "        def analyze_shells_with_uncertainty_cumulative_log_gaia(df, log_eirp_shells):\n",
    "            results = []\n",
    "            nu_rel = df['nu_rel'].mean()\n",
    "            fmin_shell = df['fmin'].min()\n",
    "            for log_shell_val in log_eirp_shells:\n",
    "                shell_val = 10**log_shell_val\n",
    "                n_stars = np.sum(df['logEIRPmin_med'] <= log_shell_val)\n",
    "                pos_err = np.sum((df['logEIRPmin_med'] > log_shell_val) & (df['logEIRPmin_lo'] <= log_shell_val))\n",
    "                neg_err = np.sum((df['logEIRPmin_med'] <= log_shell_val) & (df['logEIRPmin_hi'] > log_shell_val))\n",
    "                if n_stars == 0:\n",
    "                    pos_err = 1\n",
    "                    neg_err = 0\n",
    "                n_stars_lower = n_stars - neg_err if (n_stars - neg_err) > 0 else np.nan\n",
    "                n_stars_upper = n_stars + pos_err if (n_stars + pos_err) > 0 else np.nan\n",
    "                cwtfm = (shell_val / 1e13) * (0.5 / nu_rel) * (1000 / n_stars) if n_stars > 0 else np.nan\n",
    "                cwtfm_pos = (shell_val / 1e13) * (0.5 / nu_rel) * (1000 / n_stars_lower) if n_stars_lower > 0 else np.nan\n",
    "                cwtfm_pos_err = cwtfm_pos - cwtfm if n_stars_lower > 0 else np.nan\n",
    "                cwtfm_neg = (shell_val / 1e13) * (0.5 / nu_rel) * (1000 / n_stars_upper) if n_stars_upper > 0 else np.nan\n",
    "                cwtfm_neg_err = cwtfm - cwtfm_neg if n_stars_upper > 0 else np.nan\n",
    "                def safe_log10(x): return np.log10(x) if (x is not None and x > 0) else np.nan\n",
    "                logTR = safe_log10(1/(n_stars * nu_rel)) if n_stars > 0 else np.nan\n",
    "                logTR_pos = safe_log10(1/(n_stars_lower * nu_rel)) if n_stars_lower > 0 else np.nan\n",
    "                logTR_neg = safe_log10(1/(n_stars_upper * nu_rel)) if n_stars_upper > 0 else np.nan\n",
    "                logTR_pos_err = logTR_pos - logTR if (not np.isnan(logTR_pos) and not np.isnan(logTR)) else np.nan\n",
    "                logTR_neg_err = logTR - logTR_neg if (not np.isnan(logTR) and not np.isnan(logTR_neg)) else np.nan\n",
    "                max_dist_m = np.sqrt(shell_val / (4 * np.pi * fmin_shell))\n",
    "                max_dist_pc = max_dist_m / 3.086e16\n",
    "                results.append({\n",
    "                    'log_EIRPmin_shell': log_shell_val,\n",
    "                    'n_stars': n_stars,\n",
    "                    'n_stars_pos_err': pos_err,\n",
    "                    'n_stars_neg_err': neg_err,\n",
    "                    'log_TR': logTR,\n",
    "                    'log_TR_pos_err': logTR_pos_err,\n",
    "                    'log_TR_neg_err': logTR_neg_err,\n",
    "                    'CWTFM': cwtfm,\n",
    "                    'CWTFM_pos_err': cwtfm_pos_err,\n",
    "                    'CWTFM_neg_err': cwtfm_neg_err,\n",
    "                    'max_distance_pc': max_dist_pc\n",
    "                })\n",
    "            return pd.DataFrame(results)\n",
    "\n",
    "        if log_eirp_shells_local is None:\n",
    "            d_max_m = limit_distance_pc * 3.086e16\n",
    "            fmin_max = df_band['fmin'].max()\n",
    "            fmin_min = df_band['fmin'].min()\n",
    "            eirpmin_max = 4 * np.pi * d_max_m**2 * fmin_max\n",
    "            eirpmin_min = 4 * np.pi * (1*3.086e16)**2 * fmin_min\n",
    "            log_min = np.floor(np.log10(eirpmin_min))\n",
    "            log_max = np.ceil(np.log10(eirpmin_max))\n",
    "            shells = n_shells_local if n_shells_local is not None else 8\n",
    "            log_eirp_shells_local = np.linspace(log_min, log_max, shells)\n",
    "        else:\n",
    "            log_eirp_shells_local = log_eirp_shells_local\n",
    "\n",
    "        all_df = calculate_eirpmin_log(all_df)\n",
    "        shell_results = analyze_shells_with_uncertainty_cumulative_log_gaia(all_df, log_eirp_shells_local)\n",
    "        if output_prefix is not None:\n",
    "                all_df.to_csv(f\"{output_prefix}_gaia_df.csv\", index=False)\n",
    "                shell_results.to_csv(f\"{output_prefix}_gaia_shell_results.csv\", index=False)\n",
    "        return all_df, shell_results\n",
    "\n",
    "    # Main branch: per-band splitting or all combined\n",
    "    if split_by_band:\n",
    "        all_df_dict = {}\n",
    "        shell_results_dict = {}\n",
    "        for band_name in dataframe['receiving_band'].unique():\n",
    "            band_df = dataframe[dataframe['receiving_band'] == band_name].reset_index(drop=True)\n",
    "            out_prefix = f\"{output_prefix}_{band_name}\" if output_prefix else None\n",
    "            all_df, shell_results = run_pipeline(\n",
    "                band_df, band_name, out_prefix,\n",
    "                log_eirp_shells_outer=log_eirp_shells, n_shells_outer=n_shells)\n",
    "            all_df_dict[band_name] = all_df\n",
    "            shell_results_dict[band_name] = shell_results\n",
    "        return all_df_dict, shell_results_dict\n",
    "    else:\n",
    "        out_prefix = output_prefix\n",
    "        all_df, shell_results = run_pipeline(\n",
    "            dataframe, \"all\", out_prefix,\n",
    "            log_eirp_shells_outer=log_eirp_shells, n_shells_outer=n_shells)\n",
    "        return all_df, shell_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SETIvenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

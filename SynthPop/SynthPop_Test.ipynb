{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3065f6-e661-4ac9-82a7-459317c453d0",
   "metadata": {},
   "source": [
    "# SynthPop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d7ee319-b659-492f-a662-4b15342f956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import synthpop\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def process_synthpop(\n",
    "    dataframe,\n",
    "    limit_distance_pc=10000,\n",
    "    output_prefix=None,\n",
    "    batch_size=10,\n",
    "    max_workers=5,\n",
    "    sleep_between_batches=5,\n",
    "    n_shells=8,\n",
    "    log_eirp_shells=None,\n",
    "    config_file='huston2025_defaults.synthpop_conf',\n",
    "    split_by_band=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Parallelized, batch-based SynthPop processing with band flexibility (only processes one field at a time).\n",
    "    For field-based SETI analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pandas.DataFrame\n",
    "        Columns: ['ra', 'dec', 'fwhm_arcmin', 'fmin', 'nu_rel', 'field name', 'receiving_band']\n",
    "    limit_distance_pc : float\n",
    "        Maximum distance (pc) to include stars.\n",
    "    output_prefix : str, optional\n",
    "        Prefix for all batch result CSVs.\n",
    "    batch_size : int\n",
    "        Fields processed per batch/job.\n",
    "    max_workers : int\n",
    "        Number of parallel workers.\n",
    "    sleep_between_batches : int\n",
    "        Seconds to pause between batch launches.\n",
    "    n_shells : int\n",
    "        Number of EIRPmin shells if not providing explicit shell boundaries in log_eirp_shells.\n",
    "    log_eirp_shells : array-like, optional\n",
    "        Custom log10(EIRPmin) shell boundaries.\n",
    "    config_file : str\n",
    "        SynthPop configuration file.\n",
    "    split_by_band : bool\n",
    "        If True, process and return all_df and shell_results per unique receiving_band.\n",
    "        If False, combine all bands together (default).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    If split_by_band == False:\n",
    "        all_df : pandas.DataFrame\n",
    "        shell_results : pandas.DataFrame\n",
    "    If split_by_band == True:\n",
    "        all_df_dict : dict {band: DataFrame}\n",
    "        shell_results_dict : dict {band: DataFrame}\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The 'field name' and 'receiving_band' columns will be converted internally to string dtype to ensure\n",
    "      robust matching with SynthPop results. All other relevant columns are converted to floats  \n",
    "    - Therefore, field names, RA, DEC... can be any types convertible to strings or floats (integers, floats, or strings).\n",
    "    - Users should ensure 'field name' values are unique identifiers per unique 'receiving_band' value.\n",
    "    - Per the Wlodarczyk-Sroka et al. (2020) paper, for max distances less than 10 kpc the standard range of\n",
    "        EIRPmin shells is np.linspace(11, 18, 8)\n",
    "    - Maximum detectable distance per shell is included in shell_results.\n",
    "    - logTR and its errors are calculated for each shell based on N_stars and error propagation.\n",
    "    - If split_by_band==True, returns per-receiving_band DataFrames as dictionary entries.\n",
    "        access each DataFrame by all_df_dict['band 1']...,\n",
    "        shell_results_dict['band 1']...\n",
    "    - If split_by_band==False (default), returns combined results.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe.loc[:, 'field name'] = dataframe.loc[:, 'field name'].astype(str)\n",
    "    dataframe.loc[:, 'receiving_band'] = dataframe.loc[:, 'receiving_band'].astype(str)\n",
    "    dataframe.loc[:, 'ra'] = dataframe.loc[:, 'ra'].astype(float)\n",
    "    dataframe.loc[:, 'dec'] = dataframe.loc[:, 'dec'].astype(float)\n",
    "    dataframe.loc[:, 'fwhm_arcmin'] = dataframe.loc[:, 'fwhm_arcmin'].astype(float)\n",
    "    dataframe.loc[:, 'fmin'] = dataframe.loc[:, 'fmin'].astype(float)\n",
    "    dataframe.loc[:, 'nu_rel'] = dataframe.loc[:, 'nu_rel'].astype(float)\n",
    "\n",
    "    # Pipeline core as an inner function\n",
    "    def run_pipeline_band(\n",
    "        band_df,\n",
    "        band_name,\n",
    "        output_prefix=None,\n",
    "        config_file=config_file,\n",
    "        log_eirp_shells_outer=None,\n",
    "        n_shells_outer=None\n",
    "    ):\n",
    "        n_total = len(band_df)\n",
    "\n",
    "        def angular_separation_arcmin(beam_ra, beam_dec, star_ras, star_decs):\n",
    "            c1 = SkyCoord(beam_ra, beam_dec, unit='deg')\n",
    "            c2 = SkyCoord(star_ras, star_decs, unit='deg')\n",
    "            return c1.separation(c2).arcminute\n",
    "\n",
    "        def beam_scaling_percent(beam_ra, beam_dec, star_ras, star_decs, fwhm_arcmin):\n",
    "            theta_arcmin = angular_separation_arcmin(beam_ra, beam_dec, star_ras, star_decs, )\n",
    "            exponent = -4 * np.log(2) * (theta_arcmin / fwhm_arcmin)**2\n",
    "            scaling_factor = np.exp(exponent) * 100\n",
    "            return theta_arcmin, scaling_factor\n",
    "\n",
    "        def process_beam_vectorized(beam_ra, beam_dec, fwhm_arcmin, df):\n",
    "            df = df.copy()\n",
    "            star_ras = df['ra'].to_numpy()\n",
    "            star_decs = df['dec'].to_numpy()\n",
    "            theta, scaling = beam_scaling_percent(beam_ra, beam_dec, star_ras, star_decs, fwhm_arcmin)\n",
    "            df['theta_arcmin'] = theta\n",
    "            df['scaling_factor_percent'] = scaling\n",
    "            return df\n",
    "\n",
    "        def calculate_log_eirpmin(df):\n",
    "            log_4pi = np.log10(4 * np.pi)\n",
    "            d_m = df[\"Dist_pc\"].to_numpy() * 3.086e16  # pc to meters\n",
    "            fmin_vals = df['fmin'].to_numpy()\n",
    "            scaling_frac = df['scaling_factor_percent'].to_numpy() / 100.0\n",
    "            df['logEIRPmin'] = log_4pi + 2 * np.log10(d_m) + np.log10(fmin_vals) - np.log10(scaling_frac)\n",
    "            return df\n",
    "\n",
    "        def analyze_shells_cumulative_log_synth(df, log_eirp_shells_inner):\n",
    "            results = []\n",
    "            for log_shell_val in log_eirp_shells_inner:\n",
    "                shell_val = 10**log_shell_val\n",
    "                n_stars = np.sum(df['logEIRPmin'] <= log_shell_val)\n",
    "                n_stars_err = np.sqrt(n_stars)\n",
    "                nu_rel_shell = df['nu_rel'].mean() if n_stars > 0 else np.nan\n",
    "                cwtfm = (shell_val / 1e13) * (0.5 / nu_rel_shell) * (1000 / n_stars) if n_stars > 0 else np.nan\n",
    "                cwtfm_err = cwtfm * (n_stars_err / n_stars) if n_stars > 0 else np.nan\n",
    "                logTR = np.log10(1/(n_stars * nu_rel_shell)) if n_stars > 0 else np.nan\n",
    "                logTR_err = logTR * (n_stars_err / n_stars) if n_stars > 0 else np.nan\n",
    "                fmin_shell = df[\"fmin\"].min() if n_stars > 0 else np.nan\n",
    "                max_dist_m = np.sqrt(shell_val / (4 * np.pi * fmin_shell)) if (n_stars > 0 and fmin_shell > 0) else np.nan\n",
    "                max_dist_pc = max_dist_m / 3.086e16 if max_dist_m is not np.nan else np.nan\n",
    "                results.append({\n",
    "                    'log_EIRPmin_shell': log_shell_val,\n",
    "                    'n_stars': n_stars,\n",
    "                    'n_stars_err': n_stars_err,\n",
    "                    'log_TR': logTR,\n",
    "                    'log_TR_err': logTR_err,\n",
    "                    'CWTFM': cwtfm,\n",
    "                    'CWTFM_err': cwtfm_err,\n",
    "                    'max_distance_pc': max_dist_pc,\n",
    "                })\n",
    "            return pd.DataFrame(results)\n",
    "\n",
    "        # Shell grid\n",
    "        if log_eirp_shells_outer is None:\n",
    "            d_max_m = limit_distance_pc * 3.086e16\n",
    "            fmin_min = band_df['fmin'].min()\n",
    "            shells = n_shells_outer if n_shells_outer is not None else 8\n",
    "            eirpmin_max = 4 * np.pi * d_max_m**2 * fmin_min\n",
    "            eirpmin_min = 4 * np.pi * (1 * 3.086e16)**2 * fmin_min\n",
    "            log_min = np.floor(np.log10(eirpmin_min))\n",
    "            log_max = np.ceil(np.log10(eirpmin_max))\n",
    "            log_eirp_shells_to_use = np.linspace(log_min, log_max, shells)\n",
    "        else:\n",
    "            log_eirp_shells_to_use = log_eirp_shells_outer\n",
    "\n",
    "        # Initialize SynthPop ONCE (per band)\n",
    "        mod = synthpop.SynthPop(\n",
    "            config_file,\n",
    "            extinction_map_kwargs={'name':'maps_from_dustmaps', 'dustmap_name': 'sfd'},\n",
    "            chosen_bands=['Bessell_U', 'Bessell_B', 'Bessell_V', 'Bessell_R', 'Bessell_I',\n",
    "                        \"Gaia_G_EDR3\", \"Gaia_BP_EDR3\", \"Gaia_RP_EDR3\"],\n",
    "            maglim=['Bessell_I', 99, \"keep\"],\n",
    "            post_processing_kwargs=[{\"name\": \"ProcessDarkCompactObjects\", \"remove\": False},\n",
    "                                {\"name\": \"equatorial_coordinates\"}],\n",
    "            name_for_output='mod2test'\n",
    "        )\n",
    "        mod.init_populations()\n",
    "\n",
    "        # Batch jobs\n",
    "        batch_files = []\n",
    "        def process_sightline_batch(batch_indices, batch_idx):\n",
    "            batch_results = []\n",
    "            for i in batch_indices:\n",
    "                row = band_df.iloc[i]\n",
    "                ra_deg = float(row['ra'])\n",
    "                dec_deg = float(row['dec'])\n",
    "                fwhm_arcmin = float(row['fwhm_arcmin'])\n",
    "                field_name = str(row['field name'])\n",
    "                fmin_val = float(row['fmin'])\n",
    "                nu_rel_val = float(row['nu_rel'])\n",
    "\n",
    "                coord = SkyCoord(ra=ra_deg * u.deg, dec=dec_deg * u.deg, frame='icrs')\n",
    "                l = coord.galactic.l.deg\n",
    "                b = coord.galactic.b.deg\n",
    "                radius_deg = (fwhm_arcmin / 2) / 60\n",
    "                solid_angle_deg2 = np.pi * radius_deg**2\n",
    "                cat, distr = mod.process_location(\n",
    "                    l_deg=l, b_deg=b,\n",
    "                    solid_angle=solid_angle_deg2,\n",
    "                    solid_angle_unit='deg^2'\n",
    "                )\n",
    "                cat[\"Dist_pc\"] = cat[\"Dist\"] * 1000\n",
    "                cat = process_beam_vectorized(ra_deg, dec_deg, fwhm_arcmin, cat)\n",
    "                cat['field_name'] = field_name\n",
    "                cat['fmin'] = fmin_val\n",
    "                cat['nu_rel'] = nu_rel_val\n",
    "                cat['fwhm_arcmin'] = fwhm_arcmin\n",
    "                cat = cat[(cat[\"Dist_pc\"] <= limit_distance_pc) & (cat[\"Dist_pc\"] >= 0)].copy()\n",
    "                batch_results.append(cat)\n",
    "            if batch_results:\n",
    "                batch_df = pd.concat(batch_results, ignore_index=True)\n",
    "                if output_prefix is not None:\n",
    "                    filename = f\"{output_prefix}_{band_name}_batch{batch_idx}.csv\"\n",
    "                    batch_df.to_csv(filename, index=False)\n",
    "                    return filename\n",
    "                else:\n",
    "                    return batch_df\n",
    "            return None\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = []\n",
    "            for batch_start in range(0, n_total, batch_size):\n",
    "                batch_end = min(batch_start + batch_size, n_total)\n",
    "                batch_indices = list(range(batch_start, batch_end))\n",
    "                futures.append(executor.submit(process_sightline_batch, batch_indices, batch_start // batch_size))\n",
    "                time.sleep(sleep_between_batches)\n",
    "\n",
    "            batch_results = []\n",
    "            for future in as_completed(futures):\n",
    "                res = future.result()\n",
    "                if res is not None:\n",
    "                    batch_results.append(res)\n",
    "\n",
    "        if not batch_results:\n",
    "            print(\"No results fetched.\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "        # If output_prefix, batch_results are filenames; else, DataFrames\n",
    "        if output_prefix is not None:\n",
    "            dfs = [pd.read_csv(f) for f in batch_results]\n",
    "        else:\n",
    "            dfs = batch_results\n",
    "\n",
    "        all_df = pd.concat(dfs, ignore_index=True)\n",
    "        all_df = calculate_log_eirpmin(all_df)\n",
    "        shell_results = analyze_shells_cumulative_log_synth(all_df, log_eirp_shells_to_use)\n",
    "        drop_cols = [col for col in all_df.columns if \"eirp_boost\" in col or \"max_distance_pc_at_eirpmin\" in col]\n",
    "        all_df = all_df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "        column_to_move = all_df.pop('field_name')\n",
    "        all_df.insert(0, 'field_name', column_to_move)\n",
    "        if output_prefix is not None:\n",
    "            all_df.to_csv(f\"{output_prefix}.csv\", index=False)\n",
    "        return all_df, shell_results\n",
    "\n",
    "    # Main Logic: Split or Not by Band\n",
    "    if split_by_band:\n",
    "        all_df_dict = {}\n",
    "        shell_results_dict = {}\n",
    "        for band_name in dataframe['receiving_band'].unique():\n",
    "            df_band = dataframe[dataframe['receiving_band'] == band_name].reset_index(drop=True)\n",
    "            out_prefix = f\"{output_prefix}_{band_name}\" if output_prefix else None\n",
    "            all_df, shell_results = run_pipeline_band(\n",
    "                df_band, band_name, output_prefix=out_prefix,\n",
    "                log_eirp_shells_outer=log_eirp_shells, n_shells_outer=n_shells\n",
    "            )\n",
    "            all_df_dict[band_name] = all_df\n",
    "            shell_results_dict[band_name] = shell_results\n",
    "        return all_df_dict, shell_results_dict\n",
    "    else:\n",
    "        all_df, shell_results = run_pipeline_band(\n",
    "            dataframe, \"all\", output_prefix=output_prefix,\n",
    "            log_eirp_shells_outer=log_eirp_shells, n_shells_outer=n_shells\n",
    "        )\n",
    "        return all_df, shell_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f79dc-b083-40f6-ba48-40f89021d3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
